"""
llamaindex å®Œæ•´ragè§£å†³æ–¹æ¡ˆ
todoï¼š
    æ–‡æ¡£åˆ†å—
"""

from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core import Settings, StorageContext, load_index_from_storage, VectorStoreIndex, SimpleDirectoryReader
from llama_index.llms.huggingface import HuggingFaceLLM
import datetime
import os
import hashlib

class CompleteRAGSolution:
    def __init__(self, 
                 docs_path="/mnt/workspace/llamaindex-demo/data/åŠ³åŠ¨æ³•.pdf",
                 storage_path="/mnt/workspace/llamaindex-demo/rag/storage"):
        """
        å®Œæ•´çš„RAGè§£å†³æ–¹æ¡ˆ
        
        Args:
            docs_path: æ–‡æ¡£è·¯å¾„
            storage_path: å‘é‡å­˜å‚¨è·¯å¾„
        """
        self.docs_path = docs_path
        self.storage_path = storage_path
        self.conversation_history = []
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        self.setup_models()
        self.initialize_index()
        self.setup_chat_engine()
        
    def setup_models(self):
        """åˆå§‹åŒ–æ¨¡å‹é…ç½®"""
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
        
        # åˆå§‹åŒ–embeddingæ¨¡å‹
        self.embed_model = HuggingFaceEmbedding(
            model_name="/mnt/workspace/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        )
        
        # åˆå§‹åŒ–LLM
        self.llm = HuggingFaceLLM(
            model_name="/mnt/workspace/models/Qwen/qwen1_5_1_8b_chat_qlora_xtuner_merged",
            tokenizer_name="/mnt/workspace/models/Qwen/qwen1_5_1_8b_chat_qlora_xtuner_merged",
            model_kwargs={"trust_remote_code": True},
            tokenizer_kwargs={"trust_remote_code": True}
        )
        
        # è®¾ç½®å…¨å±€é…ç½®
        Settings.embed_model = self.embed_model
        Settings.llm = self.llm
        print("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼")
        
    def get_docs_hash(self):
        """è®¡ç®—æ–‡æ¡£å†…å®¹çš„å“ˆå¸Œå€¼ï¼Œç”¨äºæ£€æµ‹æ–‡æ¡£æ˜¯å¦æœ‰å˜åŒ–"""
        try:
            if os.path.isfile(self.docs_path):
                with open(self.docs_path, 'rb') as f:
                    content = f.read()
                return hashlib.md5(content).hexdigest()
            elif os.path.isdir(self.docs_path):
                # å¦‚æœæ˜¯ç›®å½•ï¼Œè®¡ç®—æ‰€æœ‰æ–‡ä»¶çš„å“ˆå¸Œ
                hash_obj = hashlib.md5()
                for root, dirs, files in os.walk(self.docs_path):
                    for file in sorted(files):
                        file_path = os.path.join(root, file)
                        with open(file_path, 'rb') as f:
                            hash_obj.update(f.read())
                return hash_obj.hexdigest()
        except Exception as e:
            print(f"âš ï¸ è®¡ç®—æ–‡æ¡£å“ˆå¸Œæ—¶å‡ºé”™: {e}")
            return None
            
    def save_metadata(self, docs_hash):
        """ä¿å­˜å…ƒæ•°æ®ä¿¡æ¯"""
        metadata = {
            "created_at": datetime.datetime.now().isoformat(),
            "docs_hash": docs_hash,
            "docs_path": self.docs_path,
            "embed_model": "paraphrase-multilingual-MiniLM-L12-v2",
            "llm_model": "qwen1_5_1_8b_chat_qlora_xtuner_merged"
        }
        
        metadata_path = os.path.join(self.storage_path, "metadata.json")
        try:
            import json
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å…ƒæ•°æ®å¤±è´¥: {e}")
            
    def load_metadata(self):
        """åŠ è½½å…ƒæ•°æ®ä¿¡æ¯"""
        metadata_path = os.path.join(self.storage_path, "metadata.json")
        try:
            import json
            with open(metadata_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return None
            
    def should_rebuild_index(self):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é‡å»ºç´¢å¼•"""
        # æ£€æŸ¥å­˜å‚¨ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.storage_path):
            return True, "å­˜å‚¨ç›®å½•ä¸å­˜åœ¨"
            
        # æ£€æŸ¥å…³é”®å­˜å‚¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        required_files = ["default__vector_store.json", "docstore.json", "index_store.json"]
        for file in required_files:
            if not os.path.exists(os.path.join(self.storage_path, file)):
                return True, f"ç¼ºå°‘å…³é”®æ–‡ä»¶: {file}"
        
        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦æœ‰å˜åŒ–
        current_hash = self.get_docs_hash()
        metadata = self.load_metadata()
        
        if not metadata:
            return True, "æ— å…ƒæ•°æ®ä¿¡æ¯"
            
        if current_hash and metadata.get("docs_hash") != current_hash:
            return True, "æ–‡æ¡£å†…å®¹å·²å˜åŒ–"
            
        return False, "ç´¢å¼•æ— éœ€é‡å»º"
        
    def build_index(self):
        """æ„å»ºå‘é‡ç´¢å¼•"""
        print(f"ğŸ“ æ­£åœ¨åŠ è½½æ–‡æ¡£: {self.docs_path}")
        
        # åŠ è½½æ–‡æ¡£
        if os.path.isfile(self.docs_path):
            documents = SimpleDirectoryReader(input_files=[self.docs_path]).load_data()
        elif os.path.isdir(self.docs_path):
            documents = SimpleDirectoryReader(input_dir=self.docs_path).load_data()
        else:
            raise FileNotFoundError(f"æ–‡æ¡£è·¯å¾„ä¸å­˜åœ¨: {self.docs_path}")
            
        print(f"ğŸ“„ å·²åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        print("ğŸ”§ æ­£åœ¨æ„å»ºå‘é‡ç´¢å¼•ï¼ˆè®¡ç®—æ–‡æ¡£åµŒå…¥ï¼‰...")
        
        # æ„å»ºç´¢å¼•
        self.index = VectorStoreIndex.from_documents(documents)
        
        # æŒä¹…åŒ–å­˜å‚¨
        print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜ç´¢å¼•åˆ°: {self.storage_path}")
        self.index.storage_context.persist(persist_dir=self.storage_path)
        
        # ä¿å­˜å…ƒæ•°æ®
        docs_hash = self.get_docs_hash()
        self.save_metadata(docs_hash)
        
        print("âœ… å‘é‡ç´¢å¼•æ„å»ºå¹¶ä¿å­˜å®Œæˆï¼")
        
    def load_index(self):
        """ä»å­˜å‚¨åŠ è½½å‘é‡ç´¢å¼•"""
        print(f"ğŸ“š æ­£åœ¨ä»æœ¬åœ°å­˜å‚¨åŠ è½½å‘é‡ç´¢å¼•: {self.storage_path}")
        storage_context = StorageContext.from_defaults(persist_dir=self.storage_path)
        self.index = load_index_from_storage(storage_context)
        print("âœ… å‘é‡ç´¢å¼•åŠ è½½å®Œæˆï¼")
        
    def initialize_index(self):
        """æ™ºèƒ½åˆå§‹åŒ–ç´¢å¼•ï¼ˆæ„å»ºæˆ–åŠ è½½ï¼‰"""
        print("ğŸ” æ­£åœ¨æ£€æŸ¥å‘é‡ç´¢å¼•çŠ¶æ€...")
        
        should_rebuild, reason = self.should_rebuild_index()
        
        if should_rebuild:
            print(f"ğŸš§ éœ€è¦é‡å»ºç´¢å¼•: {reason}")
            self.build_index()
        else:
            print(f"âœ… {reason}ï¼Œç›´æ¥åŠ è½½ç°æœ‰ç´¢å¼•")
            self.load_index()
            
        # æ˜¾ç¤ºç´¢å¼•ä¿¡æ¯
        metadata = self.load_metadata()
        if metadata:
            print(f"ğŸ“Š ç´¢å¼•ä¿¡æ¯: åˆ›å»ºæ—¶é—´ {metadata.get('created_at', 'æœªçŸ¥')}")
            
    def setup_chat_engine(self):
        """è®¾ç½®èŠå¤©å¼•æ“"""
        self.chat_engine = self.index.as_chat_engine(
            similarity_top_k=3  # æ£€ç´¢å‰3ä¸ªæœ€ç›¸ä¼¼çš„æ–‡æ¡£
        )
        
    def save_conversation(self, user_input, bot_response):
        """ä¿å­˜å¯¹è¯å†å²"""
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.conversation_history.append({
            "timestamp": timestamp,
            "user": user_input,
            "bot": str(bot_response)
        })

    def show_conversation_history(self):
        """æ˜¾ç¤ºå¯¹è¯å†å²"""
        if not self.conversation_history:
            print("ğŸ“ æš‚æ— å¯¹è¯å†å²")
            return
        
        print("\n" + "="*60)
        print("ğŸ“š å¯¹è¯å†å²è®°å½•")
        print("="*60)
        for i, conv in enumerate(self.conversation_history, 1):
            print(f"\nè½®æ¬¡ {i} [{conv['timestamp']}]")
            print(f"ğŸ‘¤ ç”¨æˆ·: {conv['user']}")
            print(f"ğŸ¤– åŠ©æ‰‹: {conv['bot']}")
            print("-" * 40)

    def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ”§ å¯ç”¨å‘½ä»¤")
        print("="*60)
        print("ğŸ“ /history   - æŸ¥çœ‹å¯¹è¯å†å²")
        print("ğŸ”„ /reset     - é‡ç½®å¯¹è¯ä¼šè¯")
        print("ğŸ”§ /rebuild   - å¼ºåˆ¶é‡å»ºå‘é‡ç´¢å¼•")
        print("ğŸ“Š /info      - æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯")
        print("â“ /help      - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
        print("ğŸ‘‹ /quit      - é€€å‡ºç³»ç»Ÿ")
        print("ğŸ’¡ ç›´æ¥è¾“å…¥é—®é¢˜å³å¯å¼€å§‹å¯¹è¯")
        print("="*60)

    def show_system_info(self):
        """æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ“Š ç³»ç»Ÿä¿¡æ¯")
        print("="*60)
        print(f"ğŸ“ æ–‡æ¡£è·¯å¾„: {self.docs_path}")
        print(f"ğŸ’¾ å­˜å‚¨è·¯å¾„: {self.storage_path}")
        print(f"ğŸ’¬ å¯¹è¯è½®æ¬¡: {len(self.conversation_history)}")
        
        metadata = self.load_metadata()
        if metadata:
            print(f"ğŸ• ç´¢å¼•åˆ›å»ºæ—¶é—´: {metadata.get('created_at', 'æœªçŸ¥')}")
            print(f"ğŸ”§ åµŒå…¥æ¨¡å‹: {metadata.get('embed_model', 'æœªçŸ¥')}")
            print(f"ğŸ¤– è¯­è¨€æ¨¡å‹: {metadata.get('llm_model', 'æœªçŸ¥')}")
        
        print("="*60)

    def reset_conversation(self):
        """é‡ç½®å¯¹è¯ä¼šè¯"""
        self.chat_engine.reset()
        self.conversation_history.clear()
        print("ğŸ”„ å¯¹è¯ä¼šè¯å·²é‡ç½®ï¼")
        
    def rebuild_index(self):
        """å¼ºåˆ¶é‡å»ºç´¢å¼•"""
        print("ğŸ”„ æ­£åœ¨å¼ºåˆ¶é‡å»ºå‘é‡ç´¢å¼•...")
        self.build_index()
        # é‡æ–°è®¾ç½®èŠå¤©å¼•æ“
        self.setup_chat_engine()
        # é‡ç½®å¯¹è¯å†å²
        self.reset_conversation()
        print("âœ… ç´¢å¼•é‡å»ºå®Œæˆï¼ŒèŠå¤©å¼•æ“å·²æ›´æ–°ï¼")

    def chat(self, user_input):
        """å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆå›ç­”"""
        print("ğŸ¤” æ­£åœ¨æ€è€ƒä¸­...")
        
        # ä½¿ç”¨èŠå¤©å¼•æ“è¿›è¡Œå¯¹è¯
        response = self.chat_engine.chat(user_input)
        
        # ä¿å­˜å¯¹è¯å†å²
        self.save_conversation(user_input, response)
        
        return response

    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        print("\n" + "="*80)
        print("ğŸ¯ å®Œæ•´ RAG è§£å†³æ–¹æ¡ˆ")
        print("="*80)
        print("ğŸ’¡ æ™ºèƒ½æ–‡æ¡£é—®ç­”åŠ©æ‰‹ - æ”¯æŒè‡ªåŠ¨ç´¢å¼•æ„å»ºä¸å¤šè½®å¯¹è¯")
        print("ğŸ”§ è‡ªåŠ¨æ£€æµ‹å‘é‡å­˜å‚¨çŠ¶æ€ï¼Œæ™ºèƒ½é€‰æ‹©æ„å»ºæˆ–åŠ è½½æ¨¡å¼")
        print("ğŸ“– æ”¯æŒå¤šè½®å¯¹è¯ï¼Œå¯ä»¥å‚è€ƒä¸Šä¸‹æ–‡è¿›è¡Œå›ç­”")
        print("â“ è¾“å…¥ /help æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‘½ä»¤")
        print("="*80)
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("\nğŸ‘¤ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆæˆ–è¾“å…¥å‘½ä»¤ï¼‰: ").strip()
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºè¾“å…¥
                if not user_input:
                    print("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜æˆ–å‘½ä»¤")
                    continue
                
                # å¤„ç†ç³»ç»Ÿå‘½ä»¤
                if user_input.startswith('/'):
                    command = user_input.lower()
                    
                    if command in ['/quit', '/q']:
                        print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å®Œæ•´RAGè§£å†³æ–¹æ¡ˆï¼å†è§ï¼")
                        break
                    elif command in ['/help', '/h']:
                        self.show_help()
                        continue
                    elif command == '/history':
                        self.show_conversation_history()
                        continue
                    elif command == '/reset':
                        self.reset_conversation()
                        continue
                    elif command == '/rebuild':
                        self.rebuild_index()
                        continue
                    elif command == '/info':
                        self.show_system_info()
                        continue
                    else:
                        print(f"âŒ æœªçŸ¥å‘½ä»¤: {user_input}")
                        print("ğŸ’¡ è¾“å…¥ /help æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
                        continue
                
                # å¤„ç†æ­£å¸¸å¯¹è¯
                response = self.chat(user_input)
                
                # æ˜¾ç¤ºå›ç­”
                print(f"\nğŸ¤– åŠ©æ‰‹: {response}")
                
                # æ˜¾ç¤ºç®€è¦ç»Ÿè®¡
                print(f"ğŸ’¬ å¯¹è¯è½®æ¬¡: {len(self.conversation_history)}")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ æ£€æµ‹åˆ° Ctrl+Cï¼Œæ­£åœ¨é€€å‡º...")
                break
            except Exception as e:
                print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
                print("ğŸ”„ è¯·é‡è¯•æˆ–è¾“å…¥ /help æŸ¥çœ‹å¸®åŠ©")

def main():
    """ä¸»å‡½æ•° - å¯é…ç½®æ–‡æ¡£å’Œå­˜å‚¨è·¯å¾„"""
    
    # å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹è¿™äº›è·¯å¾„
    docs_path = "/mnt/workspace/llamaindex-demo/data/åŠ³åŠ¨æ³•.pdf"  # æ–‡æ¡£è·¯å¾„
    storage_path = "/mnt/workspace/llamaindex-demo/rag/storage"   # å­˜å‚¨è·¯å¾„
    
    # åˆ›å»ºå¹¶è¿è¡Œå®Œæ•´RAGè§£å†³æ–¹æ¡ˆ
    rag_solution = CompleteRAGSolution(docs_path=docs_path, storage_path=storage_path)
    rag_solution.run()

if __name__ == "__main__":
    main() 